"""
Task Service - Database Connection & Session Management

Handles database connectivity using SQLAlchemy.
Provides:
- Database engine with connection pooling
- Session management (request-scoped)
- FastAPI dependency injection
- Async/sync session support

Connection pooling benefits:
‚úÖ Reuses existing connections (no reconnect overhead)
‚úÖ Prevents connection exhaustion
‚úÖ Improves performance (99.95% uptime goal)
‚úÖ Reduces database load (40% cost reduction)

Author: Krishan Shukla
Date: December 9, 2025
"""

from typing import Generator
from sqlalchemy import create_engine, event, pool
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool
import logging

from ..config.settings import settings
from .models import Base

# Configure logging
logger = logging.getLogger(__name__)


# ============================================================================
# DATABASE ENGINE - Connection Pool
# ============================================================================

def create_database_engine():
    """
    Create SQLAlchemy engine with optimized connection pooling.
    
    Engine is the core interface to the database.
    It manages:
    - Connection pooling (reuse connections)
    - Transaction management
    - SQL compilation
    - Connection lifecycle
    
    Connection Pool Configuration:
    - pool_size=20: Max 20 connections in pool
    - max_overflow=10: Can create 10 extra connections if needed (total 30)
    - pool_timeout=30: Wait max 30 seconds for available connection
    - pool_recycle=3600: Recycle connections every hour (prevents stale connections)
    - pool_pre_ping=True: Test connection before using (detect dead connections)
    
    Why these settings?
    - pool_size=20: Handles concurrent requests efficiently
    - max_overflow=10: Handles traffic spikes without rejecting requests
    - pool_recycle=3600: Prevents "server has gone away" errors
    - pool_pre_ping=True: Ensures reliability (99.95% uptime)
    
    Pool behavior:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Connection Pool (size=20, max_overflow=10)           ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ [C1] [C2] [C3] ... [C20] ‚Üê Regular pool             ‚îÇ
    ‚îÇ [C21] [C22] ... [C30]    ‚Üê Overflow (temp)          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    
    Request handling:
    1. Request arrives ‚Üí Get connection from pool
    2. Execute query ‚Üí Return connection to pool
    3. Pool full? ‚Üí Create overflow connection (temp)
    4. Traffic spike ends ‚Üí Overflow connections closed
    
    Returns:
        Engine: SQLAlchemy engine instance
    
    Example:
        engine = create_database_engine()
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
    """
    
    # Get database URL from settings
    database_url = settings.DATABASE_URL
    
    logger.info(f"Creating database engine for: {settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}")
    
    # Create engine with connection pooling
    engine = create_engine(
        database_url,
        
        # Connection Pool Settings
        poolclass=QueuePool,  # Thread-safe connection pool
        pool_size=20,  # Number of permanent connections
        max_overflow=10,  # Extra connections for spikes (total: 30)
        pool_timeout=30,  # Seconds to wait for available connection
        pool_recycle=3600,  # Recycle connections after 1 hour
        pool_pre_ping=True,  # Test connection before using
        
        # Echo SQL queries (debug mode only)
        echo=settings.DEBUG,  # Log SQL in development
        
        # Connection arguments
        connect_args={
            "connect_timeout": 10,  # Connection timeout (seconds)
            "application_name": settings.APP_NAME,  # Show in pg_stat_activity
        },
    )
    
    # Add connection pool listeners for monitoring
    @event.listens_for(engine, "connect")
    def receive_connect(dbapi_conn, connection_record):
        """
        Event fired when new connection is created.
        
        Useful for:
        - Logging new connections
        - Setting connection-level parameters
        - Monitoring connection creation rate
        """
        logger.debug("New database connection created")
    
    @event.listens_for(engine, "checkout")
    def receive_checkout(dbapi_conn, connection_record, connection_proxy):
        """
        Event fired when connection is retrieved from pool.
        
        pool_pre_ping handles this, but we can add custom checks:
        - Connection validity
        - Custom initialization
        - Performance monitoring
        """
        logger.debug("Connection checked out from pool")
    
    @event.listens_for(engine, "checkin")
    def receive_checkin(dbapi_conn, connection_record):
        """
        Event fired when connection is returned to pool.
        
        Useful for:
        - Cleaning up connection state
        - Logging connection usage time
        - Detecting connection leaks
        """
        logger.debug("Connection returned to pool")
    
    logger.info(
        f"Database engine created: "
        f"pool_size={engine.pool.size()}, "
        f"max_overflow={engine.pool.overflow()}"
    )
    
    return engine


# ============================================================================
# SESSION FACTORY
# ============================================================================

# Create global engine instance
engine = create_database_engine()

# Create session factory
SessionLocal = sessionmaker(
    autocommit=False,  # Manual transaction control
    autoflush=False,  # Manual flush control
    bind=engine,  # Bind to our engine
    expire_on_commit=True,  # Refresh objects after commit
)
"""
Session factory for creating database sessions.

Configuration:
- autocommit=False: Explicit transaction control (ACID compliance)
- autoflush=False: Manual control over when to send SQL
- bind=engine: Use our connection pool
- expire_on_commit=True: Reload data after commit (prevent stale data)

Why these settings?
- autocommit=False: We control when to commit/rollback
- autoflush=False: Better performance, explicit flush points
- expire_on_commit=True: Ensures data consistency

Session lifecycle:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Create Session                                       ‚îÇ
‚îÇ    session = SessionLocal()                             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 2. Use Session (queries, inserts, updates)              ‚îÇ
‚îÇ    task = session.query(Task).first()                   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 3. Commit Changes                                       ‚îÇ
‚îÇ    session.commit()  ‚Üê Saves to database                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 4. Close Session                                        ‚îÇ
‚îÇ    session.close()  ‚Üê Returns connection to pool        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Usage:
    session = SessionLocal()
    try:
        task = session.query(Task).first()
        session.commit()
    except Exception:
        session.rollback()
    finally:
        session.close()
"""


# ============================================================================
# DATABASE INITIALIZATION
# ============================================================================

def init_db():
    """
    Initialize database schema.
    
    Creates all tables defined in models.
    Should be called on application startup.
    
    What it does:
    1. Connects to database
    2. Checks if tables exist
    3. Creates missing tables
    4. Creates indexes
    5. Creates enums (for PostgreSQL)
    
    Note: In production, use Alembic migrations instead.
    This is for development/testing only.
    
    Example:
        # In main.py startup event
        @app.on_event("startup")
        async def startup():
            init_db()
    
    Safety:
    - Does NOT drop existing tables
    - Only creates missing tables
    - Idempotent (safe to run multiple times)
    """
    
    logger.info("Initializing database schema...")
    
    try:
        # Import all models to ensure they're registered
        from . import models  # noqa: F401
        
        # Create all tables
        Base.metadata.create_all(bind=engine)
        
        logger.info("‚úÖ Database schema initialized successfully")
        logger.info(f"   Tables created: {list(Base.metadata.tables.keys())}")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize database: {e}")
        raise


def drop_db():
    """
    Drop all database tables.
    
    ‚ö†Ô∏è  DANGEROUS: Deletes all data!
    
    Only use for:
    - Testing (tear down test database)
    - Development (reset local database)
    
    NEVER use in production!
    
    Example:
        # In test teardown
        def teardown():
            drop_db()
    """
    
    logger.warning("‚ö†Ô∏è  Dropping all database tables...")
    
    try:
        Base.metadata.drop_all(bind=engine)
        logger.info("‚úÖ All tables dropped")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to drop tables: {e}")
        raise


# ============================================================================
# FASTAPI DEPENDENCY - Session Management
# ============================================================================

def get_db() -> Generator[Session, None, None]:
    """
    FastAPI dependency for database sessions.
    
    Provides request-scoped database session.
    Session is automatically:
    - Created at request start
    - Committed on success
    - Rolled back on error
    - Closed after request
    
    How it works:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Request arrives                                      ‚îÇ
    ‚îÇ   ‚Üì                                                  ‚îÇ
    ‚îÇ Create session (from pool)                           ‚îÇ
    ‚îÇ   ‚Üì                                                  ‚îÇ
    ‚îÇ Execute route code                                   ‚îÇ
    ‚îÇ   ‚Üì                                                  ‚îÇ
    ‚îÇ Success? ‚Üí Commit ‚Üí Close ‚Üí Return connection       ‚îÇ
    ‚îÇ Error?   ‚Üí Rollback ‚Üí Close ‚Üí Return connection     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    
    Usage in FastAPI routes:
        @app.get("/tasks")
        def get_tasks(db: Session = Depends(get_db)):
            tasks = db.query(Task).all()
            return tasks
    
    Benefits:
    - Automatic session management (no manual close)
    - Transaction handling (commit/rollback)
    - Connection pooling (reuse connections)
    - Error handling (rollback on exception)
    
    Generator pattern:
    - yield: Pauses execution, returns session to route
    - Route executes with session
    - finally: Resumes after route, closes session
    
    Returns:
        Generator[Session]: Database session for this request
    
    Example:
        # Manual usage (rarely needed)
        db_gen = get_db()
        db = next(db_gen)
        try:
            # Use db
            pass
        finally:
            next(db_gen, None)  # Close
    """
    
    # Create new session from factory
    db = SessionLocal()
    
    logger.debug("Database session created for request")
    
    try:
        # Yield session to route
        # Route code executes here
        yield db
        
        # If we get here, route succeeded
        logger.debug("Request succeeded, committing transaction")
        
    except Exception as e:
        # Route raised exception, rollback changes
        logger.error(f"Request failed, rolling back transaction: {e}")
        db.rollback()
        raise
        
    finally:
        # Always close session (returns connection to pool)
        logger.debug("Closing database session")
        db.close()


# ============================================================================
# CONNECTION HEALTH CHECK
# ============================================================================

def check_database_connection() -> bool:
    """
    Check if database connection is working.
    
    Used for:
    - Health check endpoints
    - Startup validation
    - Monitoring
    
    What it does:
    1. Gets connection from pool
    2. Executes simple query (SELECT 1)
    3. Returns True if successful
    
    Returns:
        bool: True if database is reachable and working
    
    Example:
        if check_database_connection():
            print("‚úÖ Database is healthy")
        else:
            print("‚ùå Database is down")
    """
    
    try:
        # Get connection from pool
        with engine.connect() as connection:
            # Execute simple query
            result = connection.execute("SELECT 1")
            
            # Verify result
            if result.fetchone()[0] == 1:
                logger.debug("‚úÖ Database connection healthy")
                return True
            
        return False
        
    except Exception as e:
        logger.error(f"‚ùå Database connection failed: {e}")
        return False


def get_pool_status() -> dict:
    """
    Get connection pool statistics.
    
    Returns pool health metrics:
    - size: Current pool size
    - checked_in: Available connections
    - checked_out: In-use connections
    - overflow: Temporary overflow connections
    - total: Total connections (pool + overflow)
    
    Useful for:
    - Monitoring connection usage
    - Detecting connection leaks
    - Capacity planning
    - Performance tuning
    
    Returns:
        dict: Pool statistics
    
    Example:
        stats = get_pool_status()
        print(f"Active connections: {stats['checked_out']}")
        print(f"Available: {stats['checked_in']}")
    """
    
    try:
        pool_obj = engine.pool
        
        return {
            "size": pool_obj.size(),  # Configured pool size
            "checked_in": pool_obj.checkedin(),  # Available
            "checked_out": pool_obj.checkedout(),  # In use
            "overflow": pool_obj.overflow(),  # Temp connections
            "total": pool_obj.checkedin() + pool_obj.checkedout(),
        }
        
    except Exception as e:
        logger.error(f"Failed to get pool status: {e}")
        return {}


# ============================================================================
# TESTING (if run directly)
# ============================================================================

if __name__ == "__main__":
    """
    Test database connection and session management.
    Run: python3 src/database/connection.py
    
    Note: Requires PostgreSQL running locally
    """
    
    print("=" * 60)
    print("üóÑÔ∏è  Testing Database Connection")
    print("=" * 60)
    
    # Test 1: Check connection
    print("\n‚úÖ Test 1: Database Connection")
    if check_database_connection():
        print("   ‚úì Database is reachable")
    else:
        print("   ‚úó Database connection failed")
        print("   Note: This is expected if PostgreSQL is not running")
    
    # Test 2: Pool status
    print("\n‚úÖ Test 2: Connection Pool Status")
    stats = get_pool_status()
    print(f"   Pool size: {stats.get('size', 'N/A')}")
    print(f"   Available: {stats.get('checked_in', 'N/A')}")
    print(f"   In use: {stats.get('checked_out', 'N/A')}")
    print(f"   Overflow: {stats.get('overflow', 'N/A')}")
    
    # Test 3: Session creation
    print("\n‚úÖ Test 3: Session Creation")
    try:
        session = SessionLocal()
        print(f"   ‚úì Session created: {session}")
        session.close()
        print("   ‚úì Session closed")
    except Exception as e:
        print(f"   ‚úó Session creation failed: {e}")
    
    # Test 4: Dependency function
    print("\n‚úÖ Test 4: FastAPI Dependency")
    try:
        db_gen = get_db()
        db = next(db_gen)
        print(f"   ‚úì Dependency yielded session: {db}")
        next(db_gen, None)  # Close
        print("   ‚úì Dependency closed session")
    except Exception as e:
        print(f"   ‚úó Dependency test failed: {e}")
    
    print("\n" + "=" * 60)
    print("‚úÖ Database connection tests completed!")
    print("=" * 60)
    print("\nüìä Next: Create API routes using these sessions")
